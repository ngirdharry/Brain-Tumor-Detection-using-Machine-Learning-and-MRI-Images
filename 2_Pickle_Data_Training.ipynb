{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":1629,"status":"ok","timestamp":1681318900194,"user":{"displayName":"Komal Varale","userId":"08025479699546991618"},"user_tz":240},"id":"eBge6NtfRtSr"},"outputs":[],"source":["import os\n","from PIL import Image\n","import numpy as np\n","import pandas as pd\n","import cv2\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","import random\n","import tensorflow as tf"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26335,"status":"ok","timestamp":1681318926524,"user":{"displayName":"Komal Varale","userId":"08025479699546991618"},"user_tz":240},"id":"EPOVng36R672","outputId":"dfa51b07-0ee4-4511-b452-b42ee7699ddf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive \n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":672,"status":"ok","timestamp":1681318929055,"user":{"displayName":"Komal Varale","userId":"08025479699546991618"},"user_tz":240},"id":"PAFsfaTfSFZM","outputId":"1138c6bc-d17c-403d-d6a9-e5388fdc0e3d"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/gdrive/My Drive/Training\n","glioma_tumor  meningioma_tumor\tno_tumor  pituitary_tumor\n"]}],"source":["%cd /content/gdrive/My Drive/Training \n","!ls"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":207,"status":"ok","timestamp":1681318938260,"user":{"displayName":"Komal Varale","userId":"08025479699546991618"},"user_tz":240},"id":"MvbGqAZKS2C6"},"outputs":[],"source":["#TEST_DIR and TRAIN_DIR are the paths to the directories that contain the testing and training data, respectively.\n","#IMG_SIZE specifies the size of the images that will be used for training the model.\n","#CATEGORIES is a list that contains the different categories of images in the dataset.\n","\n","TEST_DIR = '/content/gdrive/My Drive/Testing' # test data folder\n","TRAIN_DIR = '/content/gdrive/My Drive/Training' # train data folder\n","IMG_SIZE = 150 # image size\n","CATEGORIES = [\"glioma_tumor\",\"meningioma_tumor\",\"no_tumor\",\"pituitary_tumor\"]"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":64417,"status":"ok","timestamp":1681319004896,"user":{"displayName":"Komal Varale","userId":"08025479699546991618"},"user_tz":240},"id":"UV1TkxmaTXAW","outputId":"0d478d72-d9eb-4465-dcbe-901f87c8e8df"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 826/826 [00:20<00:00, 39.44it/s] \n","100%|██████████| 822/822 [00:14<00:00, 56.54it/s] \n","100%|██████████| 395/395 [00:06<00:00, 60.27it/s] \n","100%|██████████| 827/827 [00:19<00:00, 42.59it/s] \n","/usr/local/lib/python3.9/dist-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  arr = np.asanyarray(arr)\n"]},{"name":"stdout","output_type":"stream","text":["2870\n","train\n","\n"]}],"source":["#training_data is an empty list that will be used to store the training data.\n","\n","training_data = []\n","\n","#create_training_data() is a function that reads the image files from the directories and creates training data.\n","\n","def create_training_data():\n","    #The function iterates through the CATEGORIES list and reads each image from the corresponding directory.\n","    for category in CATEGORIES: \n","\n","        path = os.path.join(TRAIN_DIR,category)  # create path \n","        class_num = CATEGORIES.index(category)  # get the classification  \n","\n","        #The image is then resized to IMG_SIZE and added to the training_data list along with its corresponding class number.\n","        for img in tqdm(os.listdir(path)): \n","        \n","          img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_COLOR)  # convert to array\n","          new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n","          training_data.append([new_array, class_num])  # add this to our training_data\n","\n","     # After all the images have been read and added to the training_data list, the list is shuffled to randomize the order of the data.       \n","    random.shuffle(training_data)\n","           \n","#create_training_data() is called to create the training data and populate the training_data list.\n","create_training_data()\n","#The training_data list is saved to a numpy binary file using the np.save() method.\n","np.save('train_data.npy', training_data)\n","#The length of the training_data list is printed to the console.   \n","print(len(training_data))\n","\n","print(\"train\")\n","print()\n","#The input features (X_train) and the target labels (Y_train) are extracted from the training_data list.\n","#X_train is a numpy array of image data (pixel values) and Y_train is a list of class numbers.\n","X_train = np.array([i[0] for i in training_data]).reshape(-1,IMG_SIZE,IMG_SIZE,3)\n","Y_train = [i[1] for i in training_data]\n","\n","#The pickle library is used to serialize the X_train and Y_train numpy arrays and save them to disk in binary format.\n","import pickle\n","\n","#The pickle_out variable is a file object opened in write binary mode (\"wb\").\n","#pickle.dump() method is used to serialize the numpy arrays and write them to the file.\n","#The file objects are then closed.\n","pickle_out = open(\"X_train.pickle\",\"wb\")\n","pickle.dump(X_train, pickle_out)\n","pickle_out.close()\n","\n","pickle_out = open(\"Y_train.pickle\",\"wb\")\n","pickle.dump(Y_train, pickle_out)\n","pickle_out.close()"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
